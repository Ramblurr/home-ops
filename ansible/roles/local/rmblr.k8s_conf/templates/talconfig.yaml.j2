#jinja2: lstrip_blocks: "true", trim_blocks: "false"
---
# {{ ansible_managed }}
clusterName: "{{ cluster_name }}"
talosVersion: "{{ cluster_talos_version }}"
kubernetesVersion: "{{ cluster_k8s_version }}"
endpoint: https://{{ cluster_apiserver_addr }}:6443
allowSchedulingOnMasters: {{ cluster_allow_schedluing_on_masters | default(false) | to_json }}
cniConfig:
  name: none
additionalApiServerCertSans:
  - {{ cluster_apiserver_addr }}
  - {{ cluster_domain_with_env }}
additionalMachineCertSans:
  - {{ cluster_apiserver_addr }}
  - {{ cluster_domain_with_env }}
clusterPodNets:
  - {{ cluster_net_pod_cidr }}
clusterSvcNets:
  - {{ cluster_net_svc_cidr }}
nodes:
{% for node in cluster_control_plane_nodes |  dict2items %}
  - hostname: cp{{ node.value.idx }}
    disableSearchDomain: true
    ipAddress: {{ node.value.ifaces.mgmt.ip }}
    installDiskSelector:
      size: "{{ cluster_control_plane_disk_selector }}"
    controlPlane: true
    nodeLabels:
      peering: "yes"
    kernelModules:
      - name: br_netfilter
        parameters:
          - nf_conntrack_max=131072
    nameservers:
{% for ns in cluster_nameservers %}
      - {{ ns }}
{% endfor %}
    networkInterfaces:
{% for iface in node.value.ifaces | dict2items %}
      - interface: eth{{ loop.index - 1 }}
        dhcp: true
        mtu: {{ iface.value.mtu }}
{% if iface.key == "mgmt" %}
        vip:
          ip: {{ cluster_apiserver_addr }}
{% endif %}
{% if iface.value.routeMetric is defined %}
        dhcpOptions:
          routeMetric: {{ iface.value.routeMetric }}
{% endif %}
{% endfor %}
{% endfor %}

{% for node in cluster_worker_nodes |  dict2items %}
  - hostname: wrk{{ node.value.idx }}
    disableSearchDomain: true
    ipAddress: {{ node.value.ifaces.mgmt.ip }}
    installDiskSelector:
      size: "{{ cluster_worker_disk_selector }}"
    controlPlane: false
    nodeLabels:
      peering: "yes"
      # https://github.com/siderolabs/talos/issues/6750
      rmblr.role/worker: "true"
    kernelModules:
      - name: br_netfilter
        parameters:
          - nf_conntrack_max=131072
    nameservers:
{% for ns in cluster_nameservers %}
      - {{ ns }}
{% endfor %}
    networkInterfaces:
{% for iface in node.value.ifaces | dict2items %}
      - interface: eth{{ loop.index - 1 }}
        dhcp: true
        mtu: {{ iface.value.mtu }}
{% if iface.value.routeMetric is defined %}
        dhcpOptions:
          routeMetric: {{ iface.value.routeMetric }}
{% endif %}
{% endfor %}
{% endfor %}

controlPlane:
  patches:
    # - |-
    #   - op: add
    #     path: /cluster/apiServer/admissionControl/0/configuration/exemptions
    #     value:
    #       namespaces:
    #         - kube-system
    #         - cilium-test
    #         - rook-ceph
    - |-
      - op: remove
        path: /cluster/apiServer/admissionControl
    - |-
      cluster:
        allowSchedulingOnMasters: true
        apiServer:
          admissionControl: []
          extraArgs:
            feature-gates: MixedProtocolLBService=true,EphemeralContainers=True
        etcd:
          subnet: "{{ cluster_node_cidr }}"
        controllerManager:
          extraArgs:
            feature-gates: MixedProtocolLBService=true,EphemeralContainers=True
        discovery:
          registries:
            service:
              disabled: true
        proxy:
          disabled: true
          extraArgs:
            feature-gates: MixedProtocolLBService=true,EphemeralContainers=True
        scheduler:
          extraArgs:
            feature-gates: MixedProtocolLBService=true,EphemeralContainers=True
      machine:
        files:
          - content: |
              [plugins]
                [plugins."io.containerd.grpc.v1.cri"]
                  enable_unprivileged_ports = true
                  enable_unprivileged_icmp = true
            path: /etc/cri/conf.d/20-customization.part
            op: create
        sysctls:
          fs.inotify.max_user_watches: "1048576"
          fs.inotify.max_user_instances: "8192"
          net.core.rmem_max: "4136960"
          net.core.wmem_max: "4136960"
        time:
          disabled: false
          servers:
            - "{{ cluster_ntp_server }}"
        network:
          extraHostEntries:
            - ip: {{ cluster_apiserver_addr }}
              aliases:
                - {{ cluster_domain_with_env }}
        kubelet:
          nodeIP:
            validSubnets:
             - {{ cluster_node_cidr }}

          extraArgs:
            feature-gates: GracefulNodeShutdown=true,MixedProtocolLBService=true,CronJobTimeZone=true
            rotate-server-certificates: "false"
            #rotate-server-certificates: "true"
worker:
  configPatches:
    - op: add
      path: /machine/kubelet/extraArgs
      value:
        feature-gates: GracefulNodeShutdown=true,MixedProtocolLBService=true,ServerSideApply=true
        # rotate-server-certificates: "true"
  inlinePatch:
    machine:
      type: worker
      kubelet:
        nodeIP:
          validSubnets:
            - {{ cluster_node_cidr }}
      sysctls:
        fs.inotify.max_user_watches: "1048576"
        fs.inotify.max_user_instances: "8192"
        net.core.rmem_max: "4136960"
        net.core.wmem_max: "4136960"
      time:
        disabled: false
        servers:
          - "{{ cluster_ntp_server }}"
